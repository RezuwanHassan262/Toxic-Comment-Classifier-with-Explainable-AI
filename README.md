# Toxic-Comment-Classifier-with-Explainable-AI

Played around with some classic ML algorithms like Logistic Regression, Support Vector Machines and Naive Bayes algorithms to classify toxic comments and then implemented XAI (LIME) to understand the model's decision-making process.


## Dataset

The dataset from the ["Toxic Comment Classification Challenge"](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview) was utilized to test those machine learning algorithms. The dataset contains a large number of Wikipedia comments that have been labeled by human raters for toxic behavior. The types of toxicity are, toxic, severe_toxic, obscene, threat, insult, and identity_hate```. 

Finally, Implemented Explainable AI LIME (Local Interpretable Model-Agnostic Explanations) to identify potential biases and improve the model's fairness and transparency.
